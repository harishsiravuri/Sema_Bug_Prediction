{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Basics and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"bug_prediction_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classname',\n",
       " 'numberOfBugsFoundUntil.',\n",
       " 'numberOfNonTrivialBugsFoundUntil.',\n",
       " 'numberOfMajorBugsFoundUntil.',\n",
       " 'numberOfCriticalBugsFoundUntil.',\n",
       " 'numberOfHighPriorityBugsFoundUntil.',\n",
       " 'bugs.x',\n",
       " 'numberOfVersionsUntil.',\n",
       " 'numberOfFixesUntil.',\n",
       " 'numberOfRefactoringsUntil.',\n",
       " 'numberOfAuthorsUntil.',\n",
       " 'linesAddedUntil.',\n",
       " 'maxLinesAddedUntil.',\n",
       " 'avgLinesAddedUntil.',\n",
       " 'linesRemovedUntil.',\n",
       " 'maxLinesRemovedUntil.',\n",
       " 'avgLinesRemovedUntil.',\n",
       " 'codeChurnUntil.',\n",
       " 'maxCodeChurnUntil.',\n",
       " 'avgCodeChurnUntil.',\n",
       " 'ageWithRespectTo.',\n",
       " 'weightedAgeWithRespectTo.',\n",
       " 'CvsEntropy',\n",
       " 'CvsWEntropy',\n",
       " 'CvsLinEntropy',\n",
       " 'CvsLogEntropy',\n",
       " 'CvsExpEntropy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.8, random_state = 1)\n",
    "test_set = data.loc[~data.index.isin(training_set.index)]\n",
    "\n",
    "data_columns = ['linesAddedUntil.', 'maxLinesAddedUntil.', 'avgLinesAddedUntil.', 'linesRemovedUntil.', 'maxLinesRemovedUntil.',\n",
    "                'avgLinesRemovedUntil.', 'codeChurnUntil.', 'maxCodeChurnUntil.', 'avgCodeChurnUntil.', 'ageWithRespectTo.',\n",
    "                'weightedAgeWithRespectTo.', 'CvsEntropy', 'CvsWEntropy', 'CvsLinEntropy', 'CvsLogEntropy', 'CvsExpEntropy']\n",
    "\n",
    "\n",
    "training_data = training_set.as_matrix(columns = data_columns)\n",
    "nan_locs = np.isnan(training_data)\n",
    "training_data[nan_locs] = 0\n",
    "\n",
    "training_target = training_set['numberOfBugsFoundUntil.'].values\n",
    "nan_locs = np.isnan(training_target)\n",
    "training_target[nan_locs] = 0\n",
    "\n",
    "test_data = test_set.as_matrix(columns = data_columns)\n",
    "nan_locs = np.isnan(test_data)\n",
    "test_data[nan_locs] = 0\n",
    "\n",
    "test_target = test_set['numberOfBugsFoundUntil.'].values\n",
    "nan_locs = np.isnan(test_target)\n",
    "test_target[nan_locs] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.640988326203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor()\n",
    "reg.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(reg.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: -0.0494088797154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(svr.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.890861672907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "kr = KernelRidge()\n",
    "kr.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(kr.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(dt.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.979818694663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 100)\n",
    "rf.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(rf.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.989124091456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(gb.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.997819140862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pr = Pipeline([('poly', PolynomialFeatures(degree = 3)),\n",
    "              ('linear', LinearRegression(fit_intercept = False))])\n",
    "\n",
    "pr.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(pr.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.8874959113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lm = Lasso()\n",
    "lm.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(lm.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.887693033752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en = ElasticNet()\n",
    "en.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(en.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Angle Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoLars\n",
    "ll = LassoLars()\n",
    "ll.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(ll.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.887922796977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "br = BayesianRidge()\n",
    "br.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(br.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: -3.769246513e+29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(training_data, training_target)\n",
    "\n",
    "print('R squared: ' + str(sgd.score(training_data, training_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
